```yaml
# -------- Tunables --------
- set_fact:
    parallelism: 5                 # how many in parallel at a time
    async_timeout: 180             # secs allowed per request
    poll_delay: 1                  # secs between polls
    poll_retries: 240              # 240 * 1s = 4 minutes max per batch
    retry_rounds: 2                # how many retry waves (parallel) for failures
    expect_status: 200

# Split the full work into batches of N
- set_fact:
    subnet_batches: "{{ all_networks_with_cluster | batch(parallelism) | list }}"

# ---------- First pass ----------
- name: Launch first-pass requests (parallel per batch)
  vars:
    current_batch: "{{ batch }}"
  block:

    - name: Start requests for this batch
      ansible.builtin.uri:
        url: "{{ qip_prod_api }}/api/v1/{{ qip_group_name }}/v4subnet.json?address={{ item.subnet }}"
        method: GET
        headers:
          Content-Type: application/json
          Authentication: "Token {{ qip_login_response.authentication }}"
        return_content: yes
        validate_certs: no
      loop: "{{ current_batch }}"
      async: "{{ async_timeout }}"
      poll: 0
      register: batch_jobs

    - name: Wait for this batch to finish
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      register: batch_results
      until: batch_results.finished
      retries: "{{ poll_retries }}"
      delay: "{{ poll_delay }}"
      loop: "{{ batch_jobs.results }}"

    - name: Collect failed and non-{{ expect_status }} items from this batch
      ansible.builtin.set_fact:
        retry_items: >-
          {{
            (
              (retry_items | default([]))
              +
              (
                batch_results.results
                | selectattr('failed','defined') | selectattr('failed')
                | map(attribute='item') | list
              )
              +
              (
                batch_results.results
                | selectattr('result.status','defined')
                | rejectattr('result.status','equalto', expect_status)
                | map(attribute='item') | list
              )
            ) | unique
          }}

  loop: "{{ subnet_batches }}"
  loop_control:
    loop_var: batch

# ---------- Retry rounds (parallel in batches) ----------
- name: Retry failures in parallel batches (round {{ round + 1 }} of {{ retry_rounds }})
  when: (retry_items | default([])) | length > 0
  vars:
    retry_batches: "{{ retry_items | batch(parallelism) | list }}"
  block:

    - name: Start retry requests for this round
      ansible.builtin.uri:
        url: "{{ qip_prod_api }}/api/v1/{{ qip_group_name }}/v4subnet.json?address={{ item.subnet }}"
        method: GET
        headers:
          Content-Type: application/json
          Authentication: "Token {{ qip_login_response.authentication }}"
        return_content: yes
        validate_certs: no
      loop: "{{ retry_batch }}"
      async: "{{ async_timeout }}"
      poll: 0
      register: retry_jobs
      loop_control:
        loop_var: retry_batch
      with_items: "{{ retry_batches }}"
      loop_control: { }  # (quiet VSCode warnings)

    - name: Flatten job handles
      ansible.builtin.set_fact:
        retry_job_handles: "{{ (retry_job_handles | default([])) + item.results }}"
      loop: "{{ retry_jobs.results }}"

    - name: Wait for retry jobs to finish
      ansible.builtin.async_status:
        jid: "{{ item.ansible_job_id }}"
      register: retry_wait
      until: retry_wait.finished
      retries: "{{ poll_retries }}"
      delay: "{{ poll_delay }}"
      loop: "{{ retry_job_handles }}"

    - name: Build next-round retry list (only items still failing)
      ansible.builtin.set_fact:
        retry_items: >-
          {{
            (
              (retry_wait.results
               | selectattr('failed','defined') | selectattr('failed')
               | map(attribute='item') | list)
              +
              (
                retry_wait.results
                | selectattr('result.status','defined')
                | rejectattr('result.status','equalto', expect_status)
                | map(attribute='item') | list
              )
            ) | unique
          }}
  loop: "{{ range(0, retry_rounds) | list }}"
  loop_control:
    loop_var: round

# ---------- Final report ----------
- name: Show any items still failing after retries
  ansible.builtin.debug:
    msg: >
      Still failing after {{ retry_rounds }} retry rounds:
      {{ (retry_items | default([])) | map(attribute='subnet') | list }}
  when: (retry_items | default([])) | length > 0

```

```py
from typing import Literal, Union, Dict, Any
from fastapi import FastAPI, HTTPException, status, Depends, Header
from pydantic import BaseModel, Field, ValidationError, root_validator
from typing_extensions import Annotated # For Python < 3.9, use from typing import Annotated

app = FastAPI()

# --- Authentication and Authorization Dependencies ---

# In a real application, you'd fetch this from a secure configuration or database
VALID_API_KEY = "your-super-secret-api-key"
AUTHORIZED_USER_ROLE = "admin" # Example role

async def verify_api_key(x_api_key: Annotated[str | None, Header()] = None):
    """
    Dependency to verify a simple API key from the 'X-API-Key' header.
    """
    if x_api_key is None or x_api_key != VALID_API_KEY:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid or missing API Key"
        )
    # In a real app, you'd fetch user details based on the key
    return {"user_id": "demo_user", "roles": [AUTHORIZED_USER_ROLE]}

async def verify_admin_role(user: Annotated[dict, Depends(verify_api_key)]):
    """
    Dependency to check if the authenticated user has the 'admin' role.
    """
    if AUTHORIZED_USER_ROLE not in user.get("roles", []):
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not authorized to perform this action"
        )
    return user

# --- Pydantic Models (Same as before) ---

class BaseConfig(BaseModel):
    """
    Base configuration model with common fields and a discriminator for OS.
    """
    os_type: Literal["windows", "linux", "macos"] = Field(
        ...,
        description="The operating system type."
    )
    version: str = Field(
        ...,
        description="The software version."
    )
    install_path: str = Field(
        ...,
        description="The installation path for the software."
    )

    @root_validator(pre=True)
    def validate_os_specific_fields(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        """
        Dynamically validates fields based on the 'os_type' value.
        This validator will dispatch to the appropriate OS-specific model for further validation.
        """
        os_type = values.get("os_type")
        if os_type == "windows":
            return WindowsConfig(**values).dict()
        elif os_type == "linux":
            return LinuxConfig(**values).dict()
        elif os_type == "macos":
            return MacOSConfig(**values).dict()
        else:
            raise ValueError(f"Unsupported OS type: {os_type}")


class WindowsConfig(BaseConfig):
    """
    Configuration model specific to Windows.
    Adds a 'registry_key' field and validates 'install_path'.
    """
    registry_key: str = Field(
        ...,
        description="Registry key specific to Windows installation."
    )

    @root_validator
    def validate_windows_path(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        install_path = values.get("install_path")
        if not install_path.startswith("C:\\") and not install_path.startswith("D:\\"):
            raise ValueError("Windows install_path must start with 'C:\\' or 'D:\\'")
        return values

class LinuxConfig(BaseConfig):
    """
    Configuration model specific to Linux.
    Adds a 'package_manager' field and validates 'install_path'.
    """
    package_manager: Literal["apt", "yum", "dnf"] = Field(
        ...,
        description="Package manager used on Linux."
    )

    @root_validator
    def validate_linux_path(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        install_path = values.get("install_path")
        if not install_path.startswith("/opt/") and not install_path.startswith("/usr/local/"):
            raise ValueError("Linux install_path must start with '/opt/' or '/usr/local/'")
        return values

class MacOSConfig(BaseConfig):
    """
    Configuration model specific to macOS.
    Adds a 'bundle_id' field and validates 'install_path'.
    """
    bundle_id: str = Field(
        ...,
        description="Bundle identifier for macOS applications."
    )

    @root_validator
    def validate_macos_path(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        install_path = values.get("install_path")
        if not install_path.startswith("/Applications/") and not install_path.startswith("/Users/"):
            raise ValueError("macOS install_path must start with '/Applications/' or '/Users/'")
        return values

# --- FastAPI Endpoint with Authentication and Authorization ---

@app.post("/secure-configure/")
async def secure_configure_system(
    config: BaseConfig,
    # The order of dependencies matters: auth/authz runs *before* Pydantic validation
    # If the dependencies raise an HTTPException, the Pydantic validation won't even be attempted.
    current_user: Annotated[dict, Depends(verify_admin_role)]
):
    """
    Endpoint to receive configuration based on OS type, protected by
    API key authentication and admin role authorization.
    """
    return {
        "message": "Configuration received successfully after auth/authz",
        "config": config.dict(),
        "authorized_by_user": current_user["user_id"]
    }

@app.exception_handler(ValidationError)
async def validation_exception_handler(request, exc: ValidationError):
    """
    Custom exception handler for Pydantic validation errors.
    """
    return HTTPException(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        detail={"errors": exc.errors()}
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

```yml
# tasks/splunk_log.yml
- name: Send custom log to Splunk if condition met
  ansible.builtin.uri:
    url: "{{ splunk_hec_url }}"
    method: POST
    headers:
      Authorization: "Splunk {{ splunk_hec_token }}"
      Content-Type: "application/json"
    body_format: json
    body:
      event: "{{ custom_log_message }}"
      sourcetype: "{{ splunk_sourcetype | default('ansible:custom_logs') }}" # Added default for sourcetype
      host: "{{ inventory_hostname }}"
      fields:
        ansible_playbook: "{{ ansible_playbook_dir | default('N/A') }}"
        ansible_task: "{{ splunk_task_name | default('send_custom_log') }}" # Added default for task name
    validate_certs: false
    status_code: 200
  when: send_splunk_log_condition | default(false) # Condition from variable
  delegate_to: localhost
  run_once: true
  tags: [ "splunk", "log_event" ]

---
- name: My Main Playbook with Splunk Logging
  hosts: your_target_hosts
  gather_facts: true

  vars:
    # Variables defined globally for this playbook
    splunk_hec_url: "https://your_splunk_hec_ip_or_hostname:8088/services/collector"
    splunk_hec_token: "YOUR_SPLUNK_HEC_TOKEN"
    send_splunk_log_condition: true # This variable controls the 'when' in splunk_log.yml
    custom_log_message: "Playbook run completed successfully."
    splunk_sourcetype: "ansible:playbook_status" # Specific sourcetype for this run
    splunk_task_name: "playbook_completion_log"

  tasks:
    - name: Run main application tasks
      ansible.builtin.debug:
        msg: "Executing main tasks..."
      # ... your primary deployment/configuration tasks ...

    - name: Include Splunk logging task
      ansensible.builtin.include_tasks:
        file: tasks/splunk_log.yml
      # No 'vars' here, as variables are inherited from the playbook's 'vars'
```
